{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "from train import adv_classifier, train, train_bound, test, adjust_lr, weights_init\n",
    "from models import modelA\n",
    "from train_vgg19 import vgg19\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings\n",
    "import pickle\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mc_predictions(model, X, nb_iter=50, batch_size=256):\n",
    "    model.train()\n",
    "    output_dim = list(model.children())[-1].out_features\n",
    "#     output_dim = list(model.children())[-1][-1].out_features # this line is for 3-channel image datasets\n",
    "    get_output = lambda data : F.softmax(model(data))\n",
    "#     get_output = lambda data : model(data)\n",
    "    X = torch.Tensor(X).to(device)\n",
    "    \n",
    "    def predict():\n",
    "        n_batches = int(np.ceil(X.shape[0] / float(batch_size)))\n",
    "        output = np.zeros(shape=(len(X), output_dim))\n",
    "        for i in range(n_batches):\n",
    "            output[i * batch_size:(i + 1) * batch_size] = get_output(X[i * batch_size:(i + 1) * batch_size]).detach().cpu().numpy()\n",
    "        return output\n",
    "\n",
    "    preds_mc = []\n",
    "    for i in tqdm(range(nb_iter)):\n",
    "        preds_mc.append(predict())\n",
    "\n",
    "    return np.asarray(preds_mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deep_representations(model, X, batch_size=256):\n",
    "    model.eval()\n",
    "    X = torch.Tensor(X).to(device)\n",
    "    # mnist modelA last hidden layer \n",
    "    last_hidden_idx = -3\n",
    "    output_dim = list(model.children())[last_hidden_idx].out_features\n",
    "\n",
    "    last_hidden_output = None\n",
    "\n",
    "    def last_hidden_hook(module, input_, output):\n",
    "        nonlocal last_hidden_output\n",
    "        last_hidden_output = output\n",
    "    \n",
    "    list(model.children())[last_hidden_idx].register_forward_hook(last_hidden_hook)\n",
    "\n",
    "    n_batches = int(np.ceil(X.shape[0] / float(batch_size)))\n",
    "    output = np.zeros(shape=(len(X), output_dim))\n",
    "    for i in tqdm(range(n_batches)):\n",
    "        model(X[i * batch_size:(i + 1) * batch_size])\n",
    "        output[i * batch_size:(i + 1) * batch_size] = last_hidden_output.detach().cpu().numpy()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_point(tup):\n",
    "    x, kde = tup\n",
    "    return kde.score_samples(np.reshape(x, (1, -1)))[0]\n",
    "\n",
    "def score_samples(kdes, samples, preds, n_jobs=None):\n",
    "    if n_jobs is not None:\n",
    "        p = mp.Pool(n_jobs)\n",
    "    else:\n",
    "        p = mp.Pool()\n",
    "    \n",
    "    results = p.map(score_point, [(x, kdes[i]) for x, i in zip(samples, preds)])\n",
    "    p.close()\n",
    "    p.join()\n",
    "\n",
    "    return results\n",
    "\n",
    "def normalize(normal, adv):\n",
    "    n_samples = len(normal)\n",
    "    total = scale(np.concatenate((normal, adv)))\n",
    "\n",
    "    return total[:n_samples], total[n_samples:]\n",
    "\n",
    "def load_list(path):\n",
    "    with open(path, \"rb\") as fp:   # Unpickling\n",
    "        b = pickle.load(fp)\n",
    "        return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LR(densities_pos, densities_neg, uncerts_pos, uncerts_neg):\n",
    "    values_neg = np.concatenate(\n",
    "        (densities_neg.reshape((1, -1)),\n",
    "         uncerts_neg.reshape((1, -1))),\n",
    "        axis=0).transpose([1, 0])\n",
    "    values_pos = np.concatenate(\n",
    "        (densities_pos.reshape((1, -1)),\n",
    "         uncerts_pos.reshape((1, -1))),\n",
    "        axis=0).transpose([1, 0])\n",
    "\n",
    "    values = np.concatenate((values_neg, values_pos))\n",
    "    labels = np.concatenate(\n",
    "        (np.zeros_like(densities_neg), np.ones_like(densities_pos)))\n",
    "\n",
    "    lr = LogisticRegressionCV(n_jobs=-1).fit(values, labels)\n",
    "\n",
    "    return values, labels, lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_roc(probs_neg, probs_pos, labels, plot=True):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    :param probs_neg:\n",
    "    :param probs_pos:\n",
    "    :param plot:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    probs = np.concatenate((probs_neg, probs_pos))\n",
    "    labels = np.concatenate((np.zeros_like(probs_neg), np.ones_like(probs_pos)))\n",
    "    fpr, tpr, _ = roc_curve(labels, probs)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    if plot:\n",
    "        plt.figure(figsize=(7, 6))\n",
    "        plt.plot(fpr, tpr, color='blue',\n",
    "                 label='ROC (AUC = %0.4f)' % auc_score)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=0.5, linestyle='--')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.title(\"ROC Curve\")\n",
    "        plt.xlabel(\"FPR\")\n",
    "        plt.ylabel(\"TPR\")\n",
    "        plt.show()\n",
    "\n",
    "    return fpr, tpr, auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_path = './example_data/mnist/org/mnist_org_train_24000.pkl'\n",
    "X_test_path = './example_data/mnist/org/mnist_org_test_6000.pkl'\n",
    "\n",
    "X_train_adv_path = './example_data/mnist/fgsm/mnist_fgsm_train_8000.pkl'\n",
    "X_test_adv_path = './example_data/mnist/fgsm/mnist_fgsm_test_2000.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = load_list(X_train_path)[0].reshape(-1, 1, 28, 28), load_list(X_train_path)[1]\n",
    "X_test, Y_test = load_list(X_test_path)[0].reshape(-1, 1, 28, 28), load_list(X_test_path)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_adv, Y_train_adv = load_list(X_train_adv_path)[0].reshape(-1, 1, 28, 28), load_list(X_train_adv_path)[1]\n",
    "X_test_adv, Y_test_adv = load_list(X_test_adv_path)[0].reshape(-1, 1, 28, 28), load_list(X_test_adv_path)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "# Gaussian kernel bandwidth for kernel density estimation\n",
    "# Authors set this value manually\n",
    "BANDWIDTHS = {'mnist': 1.20, 'cifar': 0.26}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24000, 1, 28, 28), (6000, 1, 28, 28), (24000,), (6000,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 1, 28, 28), (2000, 1, 28, 28), (8000,), (2000,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_adv.shape, X_test_adv.shape, Y_train_adv.shape, Y_test_adv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modelA(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (dropout1): Dropout(p=0.25, inplace=False)\n",
       "  (fc1): Linear(in_features=25600, out_features=128, bias=True)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = modelA()\n",
    "checkpoint = torch.load('./weights/modelA.pkl', map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint, )\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Normal Accuracy of Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on the normal train set: 100.00%\n",
      "Model accuracy on the normal test set: 100.00%\n"
     ]
    }
   ],
   "source": [
    "for s_type, dset in zip(['normal train', 'normal test'], [[X_train, Y_train], [X_test, Y_test]]):\n",
    "    model.eval()\n",
    "    \n",
    "    dset = TensorDataset(torch.Tensor(dset[0].reshape(-1, 1, 28, 28)), torch.Tensor(dset[1]))    \n",
    "    dset_loader = DataLoader(dset, batch_size=batch_size, shuffle=True, num_workers=10)\n",
    "        \n",
    "    correct = 0\n",
    "    for data, target in dset_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        pred = torch.argmax(output, 1)\n",
    "        \n",
    "        correct += (pred.detach().cpu().numpy() == target.cpu().numpy()).sum()\n",
    "        \n",
    "    acc = correct / len(dset)\n",
    "    \n",
    "    print(\"Model accuracy on the %s set: %0.2f%%\" %\n",
    "              (s_type, 100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Adversarial Accuracy of Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on the Adversarial train set: 100.00%\n",
      "Model accuracy on the Adversarial test set: 100.00%\n"
     ]
    }
   ],
   "source": [
    "for s_type, dset in zip(['Adversarial train', 'Adversarial test'], [[X_train_adv, Y_train_adv], [X_test_adv, Y_test_adv]]):\n",
    "    model.eval()\n",
    "    \n",
    "    dset = TensorDataset(torch.Tensor(dset[0].reshape(-1, 1, 28, 28)), torch.Tensor(dset[1]))    \n",
    "    dset_loader = DataLoader(dset, batch_size=batch_size, shuffle=True, num_workers=10)\n",
    "        \n",
    "    correct = 0\n",
    "    for data, target in dset_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        pred = torch.argmax(output, 1)\n",
    "        \n",
    "        correct += (pred.detach().cpu().numpy() == target.cpu().numpy()).sum()\n",
    "        \n",
    "    acc = correct / len(dset)\n",
    "    \n",
    "    print(\"Model accuracy on the %s set: %0.2f%%\" %\n",
    "              (s_type, 100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Monte Carlo dropout variance predictions...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa2c1be01bd343b2bda931bee42230c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-a9f75cc71fe1>:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  get_output = lambda data : F.softmax(model(data))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5432141c0a3c43aea872ceddc0906a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa51f0aede1482fae5bafdd31ff2cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "220df2aa240646ddb6d4831a38e09170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Unvertainty of normal trian data : 0.0005416265170089874\n",
      "Mean Unvertainty of normal test data : 0.0005702171095195299\n",
      "Mean Unvertainty of adversarial trian data : 0.007764371444358229\n",
      "Mean Unvertainty of adversarial test data : 0.007848673264638745\n"
     ]
    }
   ],
   "source": [
    "print('Getting Monte Carlo dropout variance predictions...')\n",
    "uncerts_normal_train = get_mc_predictions(model, X_train, batch_size=batch_size).var(axis=0).mean(axis=1)\n",
    "uncerts_adv_train = get_mc_predictions(model, X_train_adv, batch_size=batch_size).var(axis=0).mean(axis=1)\n",
    "uncerts_normal_test = get_mc_predictions(model, X_test, batch_size=batch_size).var(axis=0).mean(axis=1)\n",
    "uncerts_adv_test = get_mc_predictions(model, X_test_adv, batch_size=batch_size).var(axis=0).mean(axis=1)\n",
    "\n",
    "print('Mean Unvertainty of normal trian data :', uncerts_normal_train.mean())\n",
    "print('Mean Unvertainty of normal test data :', uncerts_normal_test.mean())\n",
    "print('Mean Unvertainty of adversarial trian data :', uncerts_adv_train.mean())\n",
    "print('Mean Unvertainty of adversarial test data :', uncerts_adv_test.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Deep Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting deep feature representations...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d23279396c4f1b9830f63e296f5837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=240.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9f7cb2e4ca4ffb8a81025b6435c1b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c6a0ee2fe14ca89e519f4b9f3a36c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=80.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d96f0f7d3d841049cade35c7b7c3e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean KDE of normal train data : -2.589658997529192\n",
      "Mean KDE of normal test data : -2.6040451778576132\n",
      "Mean KDE of adversarial train data : -1.5164856335851462\n",
      "Mean KDE of adversarial test data : -1.5359919322710165\n"
     ]
    }
   ],
   "source": [
    "print('Getting deep feature representations...')\n",
    "X_normal_train_features = get_deep_representations(model, X_train, batch_size=batch_size)\n",
    "X_normal_test_features = get_deep_representations(model, X_test, batch_size=batch_size)\n",
    "X_adv_train_features = get_deep_representations(model, X_train_adv, batch_size=batch_size)\n",
    "X_adv_test_features = get_deep_representations(model, X_test_adv, batch_size=batch_size)\n",
    "\n",
    "print('Mean KDE of normal train data :', X_normal_train_features.mean())\n",
    "print('Mean KDE of normal test data :', X_normal_test_features.mean())\n",
    "print('Mean KDE of adversarial train data :', X_adv_train_features.mean())\n",
    "print('Mean KDE of adversarial test data :', X_adv_test_features.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Density Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KDEs...\n",
      "Training finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-1de5a75c06ca>:7: UserWarning: Using pre-set kernel bandwidths that were determined optimal for the specific CNN models of the paper. If you've changed your model, you'll need to re-optimize the bandwidth.\n",
      "  warnings.warn(\"Using pre-set kernel bandwidths that were determined \"\n"
     ]
    }
   ],
   "source": [
    "print('Training KDEs...')\n",
    "class_inds = {}\n",
    "Y_train = np.eye(10)[Y_train]\n",
    "for i in range(Y_train.shape[1]):\n",
    "    class_inds[i] = np.where(Y_train.argmax(axis=1) == i)[0]\n",
    "kdes = {}\n",
    "warnings.warn(\"Using pre-set kernel bandwidths that were determined \"\n",
    "              \"optimal for the specific CNN models of the paper. If you've \"\n",
    "              \"changed your model, you'll need to re-optimize the \"\n",
    "              \"bandwidth.\")\n",
    "for i in range(Y_train.shape[1]):\n",
    "    kdes[i] = KernelDensity(kernel='gaussian', bandwidth=BANDWIDTHS['mnist']).fit(X_normal_train_features[class_inds[i]])\n",
    "print('Training finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing model predictions...\n",
      "Computing prediction finished!\n"
     ]
    }
   ],
   "source": [
    "# Get model predictions\n",
    "print('Computing model predictions...')\n",
    "model.eval()\n",
    "preds_train_normal = np.argmax(Y_train, 1)\n",
    "preds_test_normal = Y_test\n",
    "preds_train_adv = Y_train_adv\n",
    "preds_test_adv = Y_test_adv\n",
    "print('Computing prediction finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Sample Desities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing densities...\n"
     ]
    }
   ],
   "source": [
    "# Get density estimates\n",
    "print('computing densities...')\n",
    "stime = time.time()\n",
    "\n",
    "densities_normal_train = score_samples(\n",
    "    kdes,\n",
    "    X_normal_train_features,\n",
    "    preds_train_normal\n",
    ")\n",
    "\n",
    "densities_normal_test = score_samples(\n",
    "    kdes,\n",
    "    X_normal_test_features,\n",
    "    preds_test_normal\n",
    ")\n",
    "\n",
    "densities_adv_train = score_samples(\n",
    "    kdes,\n",
    "    X_adv_train_features,\n",
    "    preds_train_adv\n",
    ")\n",
    "\n",
    "densities_adv_test = score_samples(\n",
    "    kdes,\n",
    "    X_adv_test_features,\n",
    "    preds_test_adv\n",
    ")\n",
    "\n",
    "etime = time.time()\n",
    "print('Computing densities finished!')\n",
    "print('Elapsed time :', (etime-stime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncerts_normal_train, uncerts_normal_test\n",
    "# uncerts_adv_train, uncerts_adv_test\n",
    "# densities_normal_train, densities_normal_test\n",
    "# densities_adv_train, densities_adv_test\n",
    "\n",
    "uncerts_normal_z_train, uncerts_adv_z_train = normalize(\n",
    "    uncerts_normal_train,\n",
    "    uncerts_adv_train,\n",
    ")\n",
    "\n",
    "uncerts_normal_z_test, uncerts_adv_z_test = normalize(\n",
    "    uncerts_normal_test,\n",
    "    uncerts_adv_test,\n",
    ")\n",
    "\n",
    "densities_normal_z_train, densities_adv_z_train = normalize(\n",
    "    densities_normal_train,\n",
    "    densities_adv_train,\n",
    ")\n",
    "\n",
    "densities_normal_z_test, densities_adv_z_test = normalize(\n",
    "    densities_normal_test,\n",
    "    densities_adv_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncerts_normal_z_train.shape, uncerts_adv_z_train.shape, uncerts_normal_z_test.shape, uncerts_adv_z_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densities_normal_z_train.shape, densities_adv_z_train.shape, densities_normal_z_test.shape, densities_adv_z_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training LogisticRegression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training start...')\n",
    "\n",
    "values, labels, lr = train_LR(\n",
    "    densities_pos=densities_adv_z_train,\n",
    "    densities_neg=densities_normal_z_train,\n",
    "    uncerts_pos=uncerts_adv_z_train,\n",
    "    uncerts_neg=uncerts_normal_z_train\n",
    ")\n",
    "\n",
    "print('Training end!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_neg = np.concatenate(\n",
    "    (densities_normal_z_test.reshape((1, -1)),\n",
    "     uncerts_normal_z_test.reshape((1, -1))),\n",
    "    axis=0).transpose([1, 0])\n",
    "\n",
    "values_pos = np.concatenate(\n",
    "    (densities_adv_z_test.reshape((1, -1)),\n",
    "     uncerts_adv_z_test.reshape((1, -1))),\n",
    "    axis=0).transpose([1, 0])\n",
    "\n",
    "values = np.concatenate((values_neg, values_pos))\n",
    "labels = np.concatenate((np.zeros_like(densities_normal_z_test), np.ones_like(densities_adv_z_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluate detector\n",
    "# Compute logistic regression model predictions\n",
    "probs = lr.predict_proba(values)[:, 1]\n",
    "# Compute AUC\n",
    "n_samples = len(X_test)\n",
    "\n",
    "fpr, tpr, auc_score = compute_roc(\n",
    "    probs_neg=probs[:n_samples],\n",
    "    probs_pos=probs[n_samples:],\n",
    "    labels=labels\n",
    ")\n",
    "print('Detector ROC-AUC score: %0.5f' % auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
